{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bit20090138/miniconda3/envs/mpython/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:maml.sampling.pca:Selected first 15 PCs, explaining 99.26% variance\n",
      "INFO:maml.sampling.clustering:BirchClustering with threshold_init=0.001 and n=5 gives 5 clusters.\n",
      "INFO:maml.sampling.stratified_sampling:Finally selected 5 configurations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将 5 个中心结构写入：C5/selected.extxyz\n",
      "已将 5 行 SOAP 向量写入：C5/center_soap.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:maml.sampling.pca:Selected first 15 PCs, explaining 99.26% variance\n",
      "INFO:maml.sampling.clustering:BirchClustering with threshold_init=0.001 and n=5 gives 5 clusters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 3081 个样本\n",
      "Cluster 1: 100 个样本\n",
      "Cluster 2: 208 个样本\n",
      "Cluster 3: 85 个样本\n",
      "Cluster 4: 439 个样本\n",
      "中心索引数组： [np.int64(495), np.int64(2844), np.int64(3473), np.int64(2792), np.int64(3014)]\n",
      "Finished writing cluster 0  ->  C5/group_0.xyz\n",
      "Finished writing cluster 0 DataFrame  ->  C5/group_0.pckl.gzip\n",
      "\n",
      "Finished writing cluster 1  ->  C5/group_1.xyz\n",
      "Finished writing cluster 1 DataFrame  ->  C5/group_1.pckl.gzip\n",
      "\n",
      "Finished writing cluster 2  ->  C5/group_2.xyz\n",
      "Finished writing cluster 2 DataFrame  ->  C5/group_2.pckl.gzip\n",
      "\n",
      "Finished writing cluster 3  ->  C5/group_3.xyz\n",
      "Finished writing cluster 3 DataFrame  ->  C5/group_3.pckl.gzip\n",
      "\n",
      "Finished writing cluster 4  ->  C5/group_4.xyz\n",
      "Finished writing cluster 4 DataFrame  ->  C5/group_4.pckl.gzip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from maml.sampling.direct import BirchClustering, DIRECTSampler, SelectKFromClusters\n",
    "from dscribe.descriptors import SOAP\n",
    "from ase.io import write\n",
    "import os\n",
    "\n",
    "N_cluster = 5\n",
    "output_dir = f\"C{N_cluster}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def get_soap(atom):\n",
    "    species = ['W']\n",
    "    r_cut = 5\n",
    "    n_max = 10\n",
    "    l_max = 8\n",
    "    \n",
    "    # Setting up the SOAP descriptor\n",
    "    average_soap = SOAP(\n",
    "        species=species,\n",
    "        r_cut=r_cut,\n",
    "        n_max=n_max,\n",
    "        l_max=l_max,\n",
    "        average=\"inner\",\n",
    "        periodic=True,\n",
    "        sparse=False\n",
    "    )\n",
    "    soap_matrix = []\n",
    "    for i, iatom in enumerate(tqdm(atom, desc=\"Processing training atoms\")):\n",
    "        soap_iatom = average_soap.create(iatom)  # Compute the SOAP vector\n",
    "        soap_matrix.append(soap_iatom)  # Store the SOAP vector in the matrix\n",
    "        \n",
    "    return soap_matrix\n",
    "\n",
    "df = pd.read_pickle(\"PRM2020.pckl.gzip\", compression=\"gzip\")\n",
    "# atom  = df[\"ase_atoms\"]\n",
    "# my_soap = get_soap(atom)\n",
    "# np.save('my_soap.npy',my_soap)\n",
    "my_soap = np.load('my_soap.npy')\n",
    "\n",
    "# =========================\n",
    "# 3. 用 DIRECTSampler 找到每个簇的“中心”索引\n",
    "# =========================\n",
    "DIRECT_partitioner = DIRECTSampler(\n",
    "    structure_encoder=None,\n",
    "    clustering=BirchClustering(n=N_cluster, threshold_init=0.001),\n",
    "    select_k_from_clusters=SelectKFromClusters(selection_criteria=\"center\", n_sites=None)\n",
    ")\n",
    "DIRECT_partition = DIRECT_partitioner.fit_transform(my_soap)\n",
    "selected_indexes = DIRECT_partition['selected_indexes']  # 中心点索引（array）\n",
    "\n",
    "# 把中心对应的原子结构写到一个 extxyz 轨迹文件里\n",
    "df_center = df.iloc[selected_indexes]\n",
    "atoms_center_list = df_center[\"ase_atoms\"].tolist()\n",
    "outfile_center_xyz = os.path.join(output_dir, \"selected.extxyz\")\n",
    "write(outfile_center_xyz, atoms_center_list, format=\"extxyz\")\n",
    "\n",
    "# 保存中心结构对应的 SOAP 向量到 npy\n",
    "# 注意：my_soap 已经是二维数组了，可以这样索引\n",
    "center_soap = my_soap[selected_indexes, :]\n",
    "np.save(os.path.join(output_dir, \"center_soap.npy\"), center_soap)\n",
    "\n",
    "print(f\"已将 {len(selected_indexes)} 个中心结构写入：{outfile_center_xyz}\")\n",
    "print(f\"已将 {len(selected_indexes)} 行 SOAP 向量写入：{output_dir}/center_soap.npy\\n\")\n",
    "\n",
    "# =========================\n",
    "# 4. 再次用 DIRECTSampler，只做聚类标记（不选中心），提取 labels\n",
    "# =========================\n",
    "DIRECT_partitioner1 = DIRECTSampler(\n",
    "    structure_encoder=None,\n",
    "    clustering=BirchClustering(n=N_cluster, threshold_init=0.001),\n",
    "    select_k_from_clusters=None\n",
    ")\n",
    "DIRECT_partition1 = DIRECT_partitioner1.fit_transform(my_soap)\n",
    "\n",
    "labels = DIRECT_partition1['labels']   # 形如 array([0,1,4,1,2,0,...]), 长度 = 样本数\n",
    "unique_vals = np.unique(labels)        # 得到 [0,1,2,3,4]（因为 N_cluster=5）\n",
    "\n",
    "# 创建 一个 {簇标签: 对应索引列表} 的字典\n",
    "indices_dict = {val: np.where(labels == val)[0] for val in unique_vals}\n",
    "\n",
    "# 简单打印每个簇内包含多少个样本\n",
    "for val, idx_array in indices_dict.items():\n",
    "    print(f\"Cluster {val}: {len(idx_array)} 个样本\")\n",
    "\n",
    "print(\"中心索引数组：\", selected_indexes)  # 只是做个对比输出\n",
    "\n",
    "# =========================\n",
    "# 5. 对每个簇分别输出一个 .xyz 轨迹，以及一个 .pckl.gzip 的子 DataFrame\n",
    "# =========================\n",
    "for val in sorted(indices_dict.keys()):\n",
    "    selected_idx = indices_dict[val]              # ndarray，例如 array([12, 19, 37, ...])\n",
    "    df_sel = df.iloc[selected_idx]                # 提取属于该簇的所有行\n",
    "    atoms_list = df_sel[\"ase_atoms\"].tolist()     # ASE Atoms 对象列表\n",
    "\n",
    "    # 5.1 生成该簇的 .xyz 文件名：e.g. \"C5/group_0.xyz\"\n",
    "    filename_xyz = os.path.join(output_dir, f\"group_{val}.xyz\")\n",
    "    write(filename_xyz, atoms_list, format=\"extxyz\")\n",
    "    print(f\"Finished writing cluster {val}  ->  {filename_xyz}\")\n",
    "\n",
    "    # 5.2 生成该簇对应子 DataFrame 的 pickle 文件： e.g. \"C5/group_0.pckl.gzip\"\n",
    "    filename_pkl = os.path.join(output_dir, f\"group_{val}.pckl.gzip\")\n",
    "    df_sel.to_pickle(filename_pkl, compression='gzip', protocol=4)\n",
    "    print(f\"Finished writing cluster {val} DataFrame  ->  {filename_pkl}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
